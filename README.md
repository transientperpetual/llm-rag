# LLM-RAG

## Iteration #1

Reference - https://medium.com/@danushidk507/rag-with-llama-using-ollama-a-deep-dive-into-retrieval-augmented-generation-c58b9a1cfcd3
Execution - Successfull
Inference Quality - 2/10
TODO: Need to allow the model to use more general knowledge. A some sort of response analyser is needed to perform a quality check. Support for faiss-gpu (low priority)
